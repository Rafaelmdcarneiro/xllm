# xllm
A lightweight llama2 inference framework. It can inference llama2-7b with 166+ tokens/s on signle 4090.
